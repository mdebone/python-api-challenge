# python-api-challenge

I had some initial problems with using API keys, hiding them in a py file, but thats not secure, adding them to other . files but they wouldn't stick for whatever reason and I would always get the 400 errors, no key found so finally got this to work and was able to pull the weather data. I tried doing something I saw from a developer on a youtube video on adding a wait period after 49 extractions, as the cap on call rate is 60 requests per minute, it would add a time wait element but it didn't work well, I think it may have been nested wrong because I was always receiving no city found, moving on to next request at a pretty quick rate so I don't think it was nested correctly. I also tried and a 1.01 second time element per request, which seemed pretty clever, if the ceiling is 60 requests per minute, you're doing probably 59 requests for however many cities you need and would never hit the ceiling. I didn't get it to work, but then agian the data that I pulled on cities was a list of 625 with about 50-75 null/na/nan cities. This was about after 10-15 attempts at pulling the cities with key errors and then there were binning errors for the dictionaries that I had set up to recieve the data. 

Im pretty certain that it was not an issue with my schema of finding the route to the various items and where they were nested, like weather stuff is under temp, location stuff is under main, all of that was correct. When I say binning its because I wasn't just setting up lists to hold the latitudes and longitudes, I thought that I could take the list of the random cities I found and print it to the first column of a dataframe that would be city name, the index would be the count and the rest would be found and sorted automatically under their appropriately column header which just had a "" in there and my output wouldn't be a dictionary of lists but a dataframe, skipping a step and saving myself some time. Easy peasey.

Ohh the hubris of man. 

It didn't work, and ohh did I waist many a man-hour of attempting my very own, self-imposed, sisyphean struggle. After cutting my losses and realizing that the royal 'we' weren't making any progress, I did it as suggested, make a bunch of lists, put the data into those lists, and then after extraction append them all to a database. But I will note that even after I attempted to get that working as instruced my query url wasn't working for whatever reason. I had it set up with {imperial units}, {api key}, and {city} (because it was pulling the city name from the database I had so cleverly constructed but that wasn't working. Dropping the city request of the query url and just seeing what it returned didn't work either, I had  to requests the url, which I don't know why I was adverse to but it wasn't part of the instructions so it seemed like it was going down another road that I didn't want to go down but it actually turned out to make the request work, on the n-th attempted call. Once I had my sacred csv I made many copies and stashed it in like 5 different places, I wasn't going to lose my precious data. from there it was pretty straightforward, the only thing that thru me was at the end for the 8 charts on the params of the northern and southern hemispheres. I thought that I could just use the database and make the call directtly with the xlim of 0-90 for north and -90-0 for south. And while it was charting the scatter data for the correct hemisphere, the line of central tendency was still being written with the all of the temperature data for example, both north and south. Like if you held them side by side, the southern hemisphere line would trend down pass thru the equator and connect to the line of the graph on the right, say of the northern hemisphere. After realising that, and realising that the key here was litteraly longitude graphs, I just took the original output db, created two new ones, north and south, made sure that therer werent any cities that I lost on the equator, there weren't, my total was correct, but even if there had been I would have just done one filter function as < and one as >=. From there it was just everything repeated and pretty simple. I didn't declare the path of the png files output to the charts folder, to the best of my knowledge you can't do that when you are creating the graph with plyplot, I tried a few iterations, but they're all in there. Done purley as a housekeeping measure. 
